{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Neighbor Sampler and HGT Loader  \n",
    "- neighbor_sampler docs: [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.NeighborLoader)  \n",
    "- hgt_loader docs: [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.HGTLoader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.loader import NeighborLoader, HGTLoader\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilot Test file\n",
    "path = os.path.join(os.getcwd(), 'data/DBLP')\n",
    "dataset = DBLP(path)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's change the data for simplicity\n",
    "# leave only author and paper\n",
    "hetero_data = HeteroData()\n",
    "\n",
    "# create two node types \"author\" and \"paper\" holding a feature matrix\n",
    "hetero_data['author'].x = data['author'].x\n",
    "hetero_data['author'].train_mask = torch.full((data['author'].x.shape[0], ), True)\n",
    "\n",
    "# add train_mask (necessary for train/test split)\n",
    "hetero_data['paper'].x = data['paper'].x\n",
    "hetero_data['paper'].train_mask = torch.full((data['paper'].x.shape[0], ), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an edge type and build the graph connectivity\n",
    "# shape: (2, num_edges)\n",
    "# Let's say our edge type is ('paper', 'written_by', 'author')\n",
    "# then edge_index should look like\n",
    "# [[paper, paper, paper, ...],\n",
    "#  [author, author, author, ...]]\n",
    "# so the 1st row of edge_index is source node\n",
    "# and 2nd row of edge_index is target node (flow: source_to_target)\n",
    "hetero_data['paper', 'written_by', 'author'].edge_index = data['paper', 'to', 'author']['edge_index']\n",
    "hetero_data['author', 'write', 'paper'].edge_index = data['author', 'to', 'paper']['edge_index']\n",
    "\n",
    "del data\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mauthor\u001b[0m={\n",
      "    x=[4057, 334],\n",
      "    train_mask=[4057]\n",
      "  },\n",
      "  \u001b[1mpaper\u001b[0m={\n",
      "    x=[14328, 4231],\n",
      "    train_mask=[14328]\n",
      "  },\n",
      "  \u001b[1m(paper, written_by, author)\u001b[0m={ edge_index=[2, 19645] },\n",
      "  \u001b[1m(author, write, paper)\u001b[0m={ edge_index=[2, 19645] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(hetero_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,  ..., 14327, 14327, 14327],\n",
      "        [  262,   263,   263,  ...,   324,  1068,  3647]])\n"
     ]
    }
   ],
   "source": [
    "print(hetero_data[('paper', 'written_by', 'author')].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     1,  ...,  4054,  4055,  4056],\n",
      "        [ 2364,  6457,  2365,  ..., 13891, 13891, 13892]])\n"
     ]
    }
   ],
   "source": [
    "print(hetero_data[('author', 'write', 'paper')].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighbor Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbor sampler\n",
    "train_input_nodes = ('author', hetero_data['author'].train_mask)\n",
    "# train_input_nodes = ('paper', hetero_data['paper'].train_mask)\n",
    "kwargs = {'batch_size': 5}\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    hetero_data,\n",
    "    # Sample 1 neighbors for each node for 1 iterations\n",
    "    # it's okay to understand as num_iteration equals num_layers in graph convolutional layer\n",
    "    num_neighbors=[1] * 1,\n",
    "    shuffle=True,\n",
    "    input_nodes=train_input_nodes,\n",
    "    **kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy parameters via forwarding a single batch to the model\n",
    "device = get_device()\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device, 'edge_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mauthor\u001b[0m={\n",
      "    x=[5, 334],\n",
      "    train_mask=[5],\n",
      "    batch_size=5\n",
      "  },\n",
      "  \u001b[1mpaper\u001b[0m={\n",
      "    x=[5, 4231],\n",
      "    train_mask=[5]\n",
      "  },\n",
      "  \u001b[1m(paper, written_by, author)\u001b[0m={ edge_index=[2, 5] },\n",
      "  \u001b[1m(author, write, paper)\u001b[0m={ edge_index=[2, 0] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# you can see that the shape of edge_index is (2, 5)\n",
    "# because batch_size=5, num_neighbors=1\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mauthor\u001b[0m={\n",
      "    x=[2, 334],\n",
      "    train_mask=[2],\n",
      "    batch_size=2\n",
      "  },\n",
      "  \u001b[1mpaper\u001b[0m={\n",
      "    x=[8, 4231],\n",
      "    train_mask=[8]\n",
      "  },\n",
      "  \u001b[1m(paper, written_by, author)\u001b[0m={ edge_index=[2, 8] },\n",
      "  \u001b[1m(author, write, paper)\u001b[0m={ edge_index=[2, 0] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# let's change a little bit\n",
    "train_loader = NeighborLoader(\n",
    "    hetero_data,\n",
    "    num_neighbors=[10] * 1,\n",
    "    shuffle=True,\n",
    "    input_nodes=train_input_nodes,\n",
    "    batch_size=2,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device, 'edge_index')\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7],\n",
      "        [0, 0, 0, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# we cannot predict the actual shape of edge_index\n",
    "# because the chosen author may not have enough neighbors as you set\n",
    "print(batch[('paper', 'written_by', 'author')].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HGT Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HGTLoader` is the child class of `BaseDataLoader`  \n",
    "\n",
    "```python\n",
    "class BaseDataLoader(DataLoader):\n",
    "    r\"\"\"Extends the :class:`torch.utils.data.DataLoader` by integrating a\n",
    "    custom :meth:`self.transform_fn` function to allow transformation of a\n",
    "    returned mini-batch directly inside the main process.\n",
    "    \"\"\"\n",
    "    def _get_iterator(self) -> Iterator:\n",
    "        iterator = super()._get_iterator()\n",
    "        if hasattr(self, 'transform_fn'):\n",
    "            iterator = DataLoaderIterator(iterator, self.transform_fn)\n",
    "        return iterator\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num_samples**  \n",
    "The number of nodes\n",
    "to sample in each iteration and for each node type.  \n",
    "If given as a list, will sample the same amount of nodes for each node type.\n",
    "\n",
    "**input_nodes**  \n",
    "The indices of nodes for which neighbors are sampled to create mini-batches.  \n",
    "Needs to be passed as a tuple that holds the node type and corresponding node indices.  \n",
    "If node indices are set to :obj: `None`, all nodes of this specific type will be considered.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3022, 8517]\n"
     ]
    }
   ],
   "source": [
    "# let's find out how many papers \"author 0\" wrote\n",
    "e = hetero_data[('paper', 'written_by', 'author')].edge_index\n",
    "print(list(torch.where(e[1, :] == 0)[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since \"author 0\" has 2 neighbors\n",
    "# we can predict that the shape of batch edge_index will be (2, 2)\n",
    "# regardless of num_samples argument\n",
    "\n",
    "train_input_nodes = ('author', hetero_data['author'].train_mask)\n",
    "\n",
    "train_loader = HGTLoader(\n",
    "    hetero_data,\n",
    "    num_samples=[32] * 4,\n",
    "    # note that I set shuffle argument as False\n",
    "    shuffle=False,\n",
    "    input_nodes=train_input_nodes,\n",
    "    batch_size=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device, 'edge_index')\n",
    "print(batch[('paper', 'written_by', 'author')].edge_index.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "552df34a58977b50f46ed9443b9107dc9d4a37d849385f473aa5e5895bba112e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
