{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### anlayzing_hgt_loader  \n",
    "- docs: [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.HGTLoader)  \n",
    "- source code: [here](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/loader/hgt_loader.html#HGTLoader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Union, Dict, List, Tuple, Callable, Optional, Any\n",
    "from torch_geometric.typing import NodeType\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "from torch_geometric.loader.base import BaseDataLoader\n",
    "from torch_geometric.loader.utils import to_hetero_csc, filter_hetero_data\n",
    "from torch_geometric.loader import HGTLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HGTLoader` is the child class of `BaseDataLoader`  \n",
    "\n",
    "```python\n",
    "class BaseDataLoader(DataLoader):\n",
    "    r\"\"\"Extends the :class:`torch.utils.data.DataLoader` by integrating a\n",
    "    custom :meth:`self.transform_fn` function to allow transformation of a\n",
    "    returned mini-batch directly inside the main process.\n",
    "    \"\"\"\n",
    "    def _get_iterator(self) -> Iterator:\n",
    "        iterator = super()._get_iterator()\n",
    "        if hasattr(self, 'transform_fn'):\n",
    "            iterator = DataLoaderIterator(iterator, self.transform_fn)\n",
    "        return iterator\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGTLoader(BaseDataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: HeteroData,\n",
    "        num_samples: Union[List[int], Dict[NodeType, List[int]]],\n",
    "        input_nodes: Union[NodeType, Tuple[NodeType, Optional[Tensor]]],\n",
    "        transform: Callable = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if 'collate_fn' in kwargs:\n",
    "            del kwargs['collate_fn']\n",
    "\n",
    "        if isinstance(num_samples, (list, tuple)):\n",
    "            num_samples = {key: num_samples for key in data.node_types}\n",
    "\n",
    "        if isinstance(input_nodes, str):\n",
    "            input_nodes = (input_nodes, None)\n",
    "        assert isinstance(input_nodes, (list, tuple))\n",
    "        assert len(input_nodes) == 2\n",
    "        assert isinstance(input_nodes[0], str)\n",
    "        if input_nodes[1] is None:\n",
    "            index = torch.arange(data[input_nodes[0]].num_nodes)\n",
    "            input_nodes = (input_nodes[0], index)\n",
    "        elif input_nodes[1].dtype == torch.bool:\n",
    "            index = input_nodes[1].nonzero(as_tuple=False).view(-1)\n",
    "            input_nodes = (input_nodes[0], index)\n",
    "\n",
    "        self.data = data\n",
    "        self.num_samples = num_samples\n",
    "        self.input_nodes = input_nodes\n",
    "        self.num_hops = max([len(v) for v in num_samples.values()])\n",
    "        self.transform = transform\n",
    "        self.sample_fn = torch.ops.torch_sparse.hgt_sample\n",
    "\n",
    "        # Convert the graph data into a suitable format for sampling.\n",
    "        # NOTE: Since C++ cannot take dictionaries with tuples as key as\n",
    "        # input, edge type triplets are converted into single strings.\n",
    "        self.colptr_dict, self.row_dict, self.perm_dict = to_hetero_csc(\n",
    "            data, device='cpu')\n",
    "\n",
    "        super().__init__(input_nodes[1].tolist(), collate_fn=self.sample,\n",
    "                         **kwargs)\n",
    "\n",
    "    def sample(self, indices: List[int]) -> HeteroData:\n",
    "        input_node_dict = {self.input_nodes[0]: torch.tensor(indices)}\n",
    "        node_dict, row_dict, col_dict, edge_dict = self.sample_fn(\n",
    "            self.colptr_dict,\n",
    "            self.row_dict,\n",
    "            input_node_dict,\n",
    "            self.num_samples,\n",
    "            self.num_hops,\n",
    "        )\n",
    "        return node_dict, row_dict, col_dict, edge_dict, len(indices)\n",
    "\n",
    "    def transform_fn(self, out: Any) -> HeteroData:\n",
    "        node_dict, row_dict, col_dict, edge_dict, batch_size = out\n",
    "        data = filter_hetero_data(self.data, node_dict, row_dict, col_dict,\n",
    "                                  edge_dict, self.perm_dict)\n",
    "        data[self.input_nodes[0]].batch_size = batch_size\n",
    "\n",
    "        return data if self.transform is None else self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.pyg.org/datasets/mag_metapath2vec_emb.zip\n",
      "Extracting c:\\Users\\Youyoung\\Documents\\hetegoenous-graph-transformer\\data\\OGB_MAG\\mag\\raw\\mag_metapath2vec_emb.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "path = os.path.join(os.getcwd(), 'data/OGB_MAG')\n",
    "transform = T.ToUndirected(merge=True)\n",
    "dataset = OGB_MAG(path, preprocess='metapath2vec', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send node features/labels in advance to GPU for faster access during sampling:\n",
    "hetero_data = dataset[0].to(device, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mpaper\u001b[0m={\n",
       "    x=[736389, 128],\n",
       "    year=[736389],\n",
       "    y=[736389],\n",
       "    train_mask=[736389],\n",
       "    val_mask=[736389],\n",
       "    test_mask=[736389]\n",
       "  },\n",
       "  \u001b[1mauthor\u001b[0m={ x=[1134649, 128] },\n",
       "  \u001b[1minstitution\u001b[0m={ x=[8740, 128] },\n",
       "  \u001b[1mfield_of_study\u001b[0m={ x=[59965, 128] },\n",
       "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 1043998] },\n",
       "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 7145660] },\n",
       "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 10792672] },\n",
       "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 7505078] },\n",
       "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 1043998] },\n",
       "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 7145660] },\n",
       "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 7505078] }\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**num_samples**  \n",
    "The number of nodes\n",
    "to sample in each iteration and for each node type.  \n",
    "If given as a list, will sample the same amount of nodes for each node type.\n",
    "\n",
    "**input_nodes**  \n",
    "The indices of nodes for which neighbors are sampled to create mini-batches.  \n",
    "Needs to be passed as a tuple that holds the node type and corresponding node indices.  \n",
    "If node indices are set to :obj: `None`, all nodes of this specific type will be considered.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_nodes = ('paper', hetero_data['paper'].train_mask)\n",
    "kwargs = {'batch_size': 1024}\n",
    "\n",
    "# Sample 32 nodes per type and per iteration for 4 iterations\n",
    "\n",
    "train_loader = HGTLoader(\n",
    "    hetero_data,\n",
    "    num_samples=[32] * 4,\n",
    "    shuffle=True,\n",
    "    input_nodes=train_input_nodes,\n",
    "    **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lazy parameters via forwarding a single batch to the model:\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch.to(device, 'edge_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mpaper\u001b[0m={\n",
       "    x=[1152, 128],\n",
       "    year=[1152],\n",
       "    y=[1152],\n",
       "    train_mask=[1152],\n",
       "    val_mask=[1152],\n",
       "    test_mask=[1152],\n",
       "    batch_size=1024\n",
       "  },\n",
       "  \u001b[1mauthor\u001b[0m={ x=[128, 128] },\n",
       "  \u001b[1minstitution\u001b[0m={ x=[96, 128] },\n",
       "  \u001b[1mfield_of_study\u001b[0m={ x=[128, 128] },\n",
       "  \u001b[1m(author, affiliated_with, institution)\u001b[0m={ edge_index=[2, 11] },\n",
       "  \u001b[1m(author, writes, paper)\u001b[0m={ edge_index=[2, 143] },\n",
       "  \u001b[1m(paper, cites, paper)\u001b[0m={ edge_index=[2, 271] },\n",
       "  \u001b[1m(paper, has_topic, field_of_study)\u001b[0m={ edge_index=[2, 27] },\n",
       "  \u001b[1m(institution, rev_affiliated_with, author)\u001b[0m={ edge_index=[2, 117] },\n",
       "  \u001b[1m(paper, rev_writes, author)\u001b[0m={ edge_index=[2, 141] },\n",
       "  \u001b[1m(field_of_study, rev_has_topic, paper)\u001b[0m={ edge_index=[2, 4174] }\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "552df34a58977b50f46ed9443b9107dc9d4a37d849385f473aa5e5895bba112e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
