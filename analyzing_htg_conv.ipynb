{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing HGTconv layer  \n",
    "- source code: [here](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/hgt_conv.html#HGTConv)  \n",
    "- docs: [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.HGTConv)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**arguments**  \n",
    "- in_channels (int or Dict[str, int]) – Size of each input sample of every node type, or -1 to derive the size from the first input(s) to the forward method.\n",
    "- out_channels (int) – Size of each output sample.\n",
    "- metadata (Tuple[List[str], List[Tuple[str, str, str]]]) – The metadata of the heterogeneous graph\n",
    "- heads (int, optional) – Number of multi-head-attentions. \n",
    "- group (string, optional) – The aggregation scheme to use for grouping node embeddings generated by different relations. (sum, mean, min, max)\n",
    "- **kwargs (optional) – Additional arguments of torch_geometric.nn.conv.MessagePassing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, Dict, Optional, List\n",
    "from torch_geometric.typing import NodeType, EdgeType, Metadata\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.nn.dense import Linear\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import glorot, ones, reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGTConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Dict[str, int]],\n",
    "        out_channels: int,\n",
    "        metadata: Metadata,\n",
    "        heads: int = 1,\n",
    "        group: str = \"sum\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__(aggr='add', node_dim=0, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default value of `metadata` argument is torch_geometric.typing.  \n",
    "\n",
    "```python\n",
    "Metadata = Tuple[List[NodeType], List[EdgeType]]\n",
    "\n",
    "# example: (['author', 'paper', 'term', 'conference'], [('author', 'to', 'paper'), (), ()...])\n",
    "```\n",
    "\n",
    "so the first element of `metadata` is the list of node types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init method continues as follows...\n",
    "\n",
    "```python\n",
    "    # metadata[0] represents the list of node types\n",
    "    # ex) ['author', 'paper', 'term', 'conference']\n",
    "    if not isinstance(in_channels, dict):\n",
    "        in_channels = {node_type: in_channels for node_type in metadata[0]}\n",
    "\n",
    "    self.in_channels = in_channels\n",
    "    self.out_channels = out_channels\n",
    "    self.heads = heads\n",
    "    self.group = group\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`in_channels` are same regardless of node type because **linear dict** will be applied before using `HGTConv` layer.  \n",
    "`in_channels` will be used to all linear layers (k_in, q_lin, v_lin, a_lin).\n",
    "\n",
    "```python\n",
    "    self.k_lin = torch.nn.ModuleDict()\n",
    "    self.q_lin = torch.nn.ModuleDict()\n",
    "    self.v_lin = torch.nn.ModuleDict()\n",
    "    self.a_lin = torch.nn.ModuleDict()\n",
    "    self.skip = torch.nn.ParameterDict()\n",
    "\n",
    "    for node_type, in_channels in self.in_channels.items():\n",
    "        self.k_lin[node_type] = Linear(in_channels, out_channels)\n",
    "        self.q_lin[node_type] = Linear(in_channels, out_channels)\n",
    "        self.v_lin[node_type] = Linear(in_channels, out_channels)\n",
    "        self.a_lin[node_type] = Linear(out_channels, out_channels)\n",
    "        self.skip[node_type] = Parameter(torch.Tensor(1))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`a_rel` means relation parameter matrix for attention: $W^{ATT}$,  \n",
    "`m_rel` means relation parameter matrix for message: $W^{MSG}$,  \n",
    "`p_rel` means position encoding parameter matrix  \n",
    "\n",
    "```python\n",
    "    self.a_rel = torch.nn.ParameterDict()\n",
    "    self.m_rel = torch.nn.ParameterDict()\n",
    "    self.p_rel = torch.nn.ParameterDict()\n",
    "\n",
    "    dim = out_channels // heads\n",
    "    for edge_type in metadata[1]:\n",
    "        edge_type = '__'.join(edge_type)\n",
    "        self.a_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))\n",
    "        self.m_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))\n",
    "        self.p_rel[edge_type] = Parameter(torch.Tensor(heads))\n",
    "```\n",
    "\n",
    "so the **init method** ends here  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see **forward** method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "    self,\n",
    "    x_dict: Dict[NodeType, Tensor],\n",
    "    edge_index_dict: Union[Dict[EdgeType, Tensor],\n",
    "                            Dict[EdgeType, SparseTensor]]  # Support both.\n",
    ") -> Dict[NodeType, Optional[Tensor]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given `x_dict` and `edge_index_dict`,  \n",
    "\n",
    "```\n",
    "x_dict\n",
    " A dictionary holding input node features for each individual node type.\n",
    "\n",
    "edge_index_dict\n",
    " A dictionary holding graph connectivity information for each\n",
    " individual edge type, either as a `torch.LongTensor` of\n",
    " shape [2, num_edges] or a `torch_sparse.SparseTensor`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `x_dict` represents $H^{l-1}$ which means node feature matrix of layer $l-1$  \n",
    "\n",
    "```python\n",
    "    H, D = self.heads, self.out_channels // self.heads\n",
    "\n",
    "    k_dict, q_dict, v_dict, out_dict = {}, {}, {}, {}\n",
    "\n",
    "    # 1) pass through k/q/v linear layer\n",
    "    for node_type, x in x_dict.items():\n",
    "        k_dict[node_type] = self.k_lin[node_type](x).view(-1, H, D)\n",
    "        q_dict[node_type] = self.q_lin[node_type](x).view(-1, H, D)\n",
    "        v_dict[node_type] = self.v_lin[node_type](x).view(-1, H, D)\n",
    "        out_dict[node_type] = []\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we should do is that \n",
    "\n",
    "```python\n",
    "    # 2) Iterate over edge-types\n",
    "    # Example\n",
    "    # data.edge_index_dict[('author', 'to', 'paper')].shape -> (2, 19645)\n",
    "    for edge_type, edge_index in edge_index_dict.items():\n",
    "        src_type, _, dst_type = edge_type\n",
    "        edge_type = '__'.join(edge_type)\n",
    "\n",
    "        # ready for heterogenous mutual attention\n",
    "        a_rel = self.a_rel[edge_type]\n",
    "        k = (k_dict[src_type].transpose(0, 1) @ a_rel).transpose(1, 0)\n",
    "\n",
    "        # ready for heterogenous message passing\n",
    "        m_rel = self.m_rel[edge_type]\n",
    "        v = (v_dict[src_type].transpose(0, 1) @ m_rel).transpose(1, 0)\n",
    "\n",
    "        # propagate_type: (k: Tensor, q: Tensor, v: Tensor, rel: Tensor)\n",
    "        out = self.propagate(\n",
    "            edge_index, k=k, q=q_dict[dst_type], v=v,\n",
    "            rel=self.p_rel[edge_type], size=None)\n",
    "        out_dict[dst_type].append(out)\n",
    "```\n",
    "\n",
    "Here we must check the **message** method first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def message(\n",
    "    self,\n",
    "    k_j: Tensor, q_i: Tensor, v_j: Tensor, rel: Tensor,\n",
    "    index: Tensor,\n",
    "    ptr: Optional[Tensor],\n",
    "    size_i: Optional[int]\n",
    "    ) -> Tensor:\n",
    "\n",
    "    alpha = (q_i * k_j).sum(dim=-1) * rel\n",
    "    alpha = alpha / math.sqrt(q_i.size(-1))\n",
    "    alpha = softmax(alpha, index, ptr, size_i)\n",
    "    out = v_j * alpha.view(-1, self.heads, 1)\n",
    "    return out.view(-1, self.out_channels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # 3) Iterate over node-types\n",
    "    for node_type, outs in out_dict.items():\n",
    "        out = group(outs, self.group)\n",
    "\n",
    "        if out is None:\n",
    "            out_dict[node_type] = None\n",
    "            continue\n",
    "\n",
    "        out = self.a_lin[node_type](F.gelu(out))\n",
    "        if out.size(-1) == x_dict[node_type].size(-1):\n",
    "            alpha = self.skip[node_type].sigmoid()\n",
    "            out = alpha * out + (1 - alpha) * x_dict[node_type]\n",
    "        out_dict[node_type] = out\n",
    "\n",
    "    return out_dict\n",
    "```\n",
    "\n",
    "**group** function is like this:\n",
    "\n",
    "```python\n",
    "def group(xs: List[Tensor], aggr: Optional[str]) -> Optional[Tensor]:\n",
    "    if len(xs) == 0:\n",
    "        return None\n",
    "    elif aggr is None:\n",
    "        return torch.stack(xs, dim=1)\n",
    "    elif len(xs) == 1:\n",
    "        return xs[0]\n",
    "    else:\n",
    "        out = torch.stack(xs, dim=0)\n",
    "        out = getattr(torch, aggr)(out, dim=0)\n",
    "        out = out[0] if isinstance(out, tuple) else out\n",
    "        return out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "552df34a58977b50f46ed9443b9107dc9d4a37d849385f473aa5e5895bba112e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
